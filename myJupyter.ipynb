{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4244387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\n",
      "target: (16, 17)\n",
      "opinion: (15, 15)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['it', 'is', 'of', 'high', 'quality', ',', 'has', 'a', 'killer', 'GUI', ',', 'is', 'extremely', 'stable', ',', 'is', 'highly', 'expandable', ',', 'is', 'bundled', 'with', 'lots', 'of', 'very', 'good', 'applications', ',', 'is', 'easy', 'to', 'use', ',', 'and', 'is', 'absolutely', 'gorgeous', '.']\n",
      "target: (4, 4)\n",
      "opinion: (3, 3)\n",
      "label: LabelEnum.positive\n",
      "target: (9, 9)\n",
      "opinion: (8, 8)\n",
      "label: LabelEnum.positive\n",
      "target: (26, 26)\n",
      "opinion: (25, 25)\n",
      "label: LabelEnum.positive\n",
      "target: (31, 31)\n",
      "opinion: (29, 29)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['Easy', 'to', 'start', 'up', 'and', 'does', 'not', 'overheat', 'as', 'much', 'as', 'other', 'laptops', '.']\n",
      "target: (2, 3)\n",
      "opinion: (0, 0)\n",
      "label: LabelEnum.positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Data Exploration\n",
    "data_name = \"14lap\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from data_utils import Data\n",
    "\n",
    "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "data = Data.load_from_full_path(path)\n",
    "\n",
    "for s in data.sentences[:3]:\n",
    "    print(\"tokens:\", s.tokens)\n",
    "    for t in s.triples:\n",
    "        print(\"target:\", (t.t_start, t.t_end))\n",
    "        print(\"opinion:\", (t.o_start, t.o_end))\n",
    "        print(\"label:\", t.label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c754712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'cd /home/lid/MySpanASTE && allennlp predict pretrained_14lap/weights/model.tar.gz /home/lid/MySpanASTE/pretrained_14lap/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file pretrained_14lap/temp_data/pred_out.json --cuda-device 0 --silent '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:53:45,613 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-08-13 16:53:45,748 - INFO - allennlp.models.archival - loading archive file pretrained_14lap/weights/model.tar.gz\n",
      "2022-08-13 16:53:45,749 - INFO - allennlp.models.archival - extracting archive file pretrained_14lap/weights/model.tar.gz to temp dir /tmp/tmp2f71xd3m\n",
      "2022-08-13 16:53:48,393 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2022-08-13 16:53:48,394 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2022-08-13 16:53:58,562 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2022-08-13 16:53:58,562 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2022-08-13 16:53:58,562 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2022-08-13 16:53:58,562 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-08-13 16:53:58,562 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2022-08-13 16:53:58,563 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2022-08-13 16:53:58,564 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-08-13 16:53:58,564 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp2f71xd3m/vocabulary.\n",
      "2022-08-13 16:53:58,566 - INFO - allennlp.common.params - model.type = span_model\n",
      "2022-08-13 16:53:58,566 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2022-08-13 16:53:58,567 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2022-08-13 16:54:02,286 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.max_span_width = 8\n",
      "2022-08-13 16:54:02,287 - INFO - allennlp.common.params - model.target_task = relation\n",
      "2022-08-13 16:54:02,288 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f2c01863750>\n",
      "2022-08-13 16:54:02,288 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2022-08-13 16:54:02,288 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2022-08-13 16:54:02,288 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2022-08-13 16:54:02,288 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2022-08-13 16:54:02,288 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.use_ner_embeds = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.use_double_mix_embedder = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.relation_head_type = proper\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.use_bi_affine = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.neg_class_weight = -1\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.use_focal_loss = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.use_double_scorer = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.use_single_pool = False\n",
      "2022-08-13 16:54:02,289 - INFO - allennlp.common.params - ner.name = ner_labels\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.neg_class_weight = -1\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_pruning = True\n",
      "2022-08-13 16:54:02,292 - INFO - allennlp.common.params - relation.use_single_pool = False\n",
      "2022-08-13 16:54:02,298 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-08-13 16:54:02,298 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,300 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-08-13 16:54:02,300 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-08-13 16:54:02,301 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,301 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,304 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,304 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
      "2022-08-13 16:54:02,304 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2022-08-13 16:54:02,304 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-08-13 16:54:02,304 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-08-13 16:54:02,305 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-08-13 16:54:02,305 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
      "2022-08-13 16:54:02,305 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,306 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,307 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,308 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,309 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,310 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-08-13 16:54:02,311 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-08-13 16:54:02,312 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
      "2022-08-13 16:54:02,313 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:54:04,232 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-08-13 16:54:04,374 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp2f71xd3m\n",
      "reading instances: 1it [00:00, 211.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "################################################################################\n",
      "{'locals': ('use_ner_embeds', False)}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_double_mix_embedder', False)}\n",
      "{'locals': ('relation_head_type', 'proper')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f2bc4859560>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__tag_labels, Size: 9 || None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n",
      "{'file_path': '/home/lid/MySpanASTE/pretrained_14lap/temp_data/pred_in.json', 'stats': Stats(entity_total=1, entity_drop=0, relation_total=1, relation_drop=0, graph_total=0, graph_edges=0, grid_total=121, grid_paired=1)}\n",
      "\n",
      "{'target': 'Windows 8', 'opinion': 'not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
      "\n",
      "{'target': 'touchscreen functions', 'opinion': 'not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n"
     ]
    }
   ],
   "source": [
    "# Use pretrained SpanModel weights for prediction\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from pathlib import Path\n",
    "from data_utils import Data, Sentence, SplitEnum\n",
    "from wrapper import SpanModel\n",
    "\n",
    "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
    "    path_in = \"temp_in.txt\"\n",
    "    path_out = \"temp_out.txt\"\n",
    "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
    "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
    "    data.save_to_path(path_in)\n",
    "    model.predict(path_in, path_out)\n",
    "    data = Data.load_from_full_path(path_out)\n",
    "    return data.sentences[0]\n",
    "\n",
    "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
    "model = SpanModel(save_dir=\"pretrained_14lap\", random_seed=0)\n",
    "sent = predict_sentence(text, model)\n",
    "\n",
    "for t in sent.triples:\n",
    "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
    "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
    "    print()\n",
    "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79984d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
    "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
    "save_dir = f\"outputs/{data_name}/seed_{random_seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d1e0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'cd /home/lid/MySpanASTE && allennlp predict pretrained_14lap/weights/model.tar.gz /home/lid/MySpanASTE/pretrained_14lap/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file pretrained_14lap/temp_data/pred_out.json --cuda-device 0 --silent '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:56:27,760 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-08-13 16:56:27,898 - INFO - allennlp.models.archival - loading archive file pretrained_14lap/weights/model.tar.gz\n",
      "2022-08-13 16:56:27,898 - INFO - allennlp.models.archival - extracting archive file pretrained_14lap/weights/model.tar.gz to temp dir /tmp/tmp61x24_qr\n",
      "2022-08-13 16:56:30,567 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2022-08-13 16:56:30,568 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2022-08-13 16:56:40,035 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-08-13 16:56:40,036 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp61x24_qr/vocabulary.\n",
      "2022-08-13 16:56:40,037 - INFO - allennlp.common.params - model.type = span_model\n",
      "2022-08-13 16:56:40,037 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2022-08-13 16:56:40,037 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2022-08-13 16:56:40,038 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2022-08-13 16:56:43,895 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False\n",
      "2022-08-13 16:56:43,896 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.max_span_width = 8\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.target_task = relation\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f0b1fa5b3d0>\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2022-08-13 16:56:43,897 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.use_ner_embeds = False\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.use_double_mix_embedder = False\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.relation_head_type = proper\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - ner.use_bi_affine = False\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - ner.neg_class_weight = -1\n",
      "2022-08-13 16:56:43,898 - INFO - allennlp.common.params - ner.use_focal_loss = False\n",
      "2022-08-13 16:56:43,899 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2\n",
      "2022-08-13 16:56:43,899 - INFO - allennlp.common.params - ner.use_double_scorer = False\n",
      "2022-08-13 16:56:43,899 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False\n",
      "2022-08-13 16:56:43,899 - INFO - allennlp.common.params - ner.use_single_pool = False\n",
      "2022-08-13 16:56:43,899 - INFO - allennlp.common.params - ner.name = ner_labels\n",
      "2022-08-13 16:56:43,900 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.neg_class_weight = -1\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_pruning = True\n",
      "2022-08-13 16:56:43,901 - INFO - allennlp.common.params - relation.use_single_pool = False\n",
      "2022-08-13 16:56:43,908 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-08-13 16:56:43,908 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,910 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-08-13 16:56:43,910 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,911 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,914 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,915 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
      "2022-08-13 16:56:43,915 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2022-08-13 16:56:43,915 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-08-13 16:56:43,915 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-08-13 16:56:43,915 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-08-13 16:56:43,915 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
      "2022-08-13 16:56:43,915 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-08-13 16:56:43,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-08-13 16:56:43,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,918 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-08-13 16:56:43,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,921 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-08-13 16:56:43,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
      "2022-08-13 16:56:43,924 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 16:56:45,850 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2022-08-13 16:56:45,985 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp61x24_qr\n",
      "reading instances: 328it [00:00, 2266.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "################################################################################\n",
      "{'locals': ('use_ner_embeds', False)}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_double_mix_embedder', False)}\n",
      "{'locals': ('relation_head_type', 'proper')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f0af2a5f560>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__tag_labels, Size: 9 || None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n",
      "{'file_path': '/home/lid/MySpanASTE/pretrained_14lap/temp_data/pred_in.json', 'stats': Stats(entity_total=328, entity_drop=0, relation_total=328, relation_drop=0, graph_total=0, graph_edges=0, grid_total=110829, grid_paired=328)}\n",
      "{\n",
      "  \"path_pred\": \"pred.txt\",\n",
      "  \"path_gold\": \"aste/data/triplet_data/14lap/test.txt\",\n",
      "  \"precision\": 0.6376811594202898,\n",
      "  \"recall\": 0.567219152854512,\n",
      "  \"score\": 0.6003898635477581\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SpanModel F1 Score\n",
    "import json\n",
    "\n",
    "path_pred = \"pred.txt\"\n",
    "model.predict(path_in=path_test, path_out=path_pred)\n",
    "results = model.score(path_pred, path_test)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2db940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
